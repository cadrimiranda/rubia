# Resolu√ß√£o do Problema de Thread Pool Exhaustion no Sistema de Campanhas WhatsApp

## üìã Contexto Inicial

**Data**: 09/08/2025  
**Problema**: Campanhas de WhatsApp com 4 contatos demoravam 3 minutos e paravam ap√≥s processar apenas 2 contatos.

### An√°lise dos Logs
```
21:54 - In√≠cio da campanha com 4 contatos
22:01 - Sistema parou ap√≥s enviar apenas 2 mensagens
```

**Evid√™ncia dos logs**: O sistema estava processando apenas 2 itens e depois travava completamente.

---

## üîç Root Cause Analysis

### Thread Pool Exhaustion Identificado

**Configura√ß√£o original**:
```java
executor.setCorePoolSize(2);  // Apenas 2 threads core
executor.setMaxPoolSize(4);   // M√°ximo 4 threads
```

**Problema encontrado**:
```java
// CampaignMessagingService.java - M√©todo performActualSendWithRetry()
if (attempt < maxRetries) {
    log.warn("Tentativa {} falhou. Tentando novamente em {}ms", attempt, retryDelay);
    Thread.sleep(retryDelay); // ‚ùå BLOQUEANTE - Consumia as 2 threads
    continue;
}
```

**Resultado**: Com apenas 2 core threads e `Thread.sleep(5000ms)` bloqueando ambas, o sistema ficava sem threads dispon√≠veis para processar novos itens da fila.

---

## ‚ö†Ô∏è Primeira Solu√ß√£o (Inadequada)

### Minha Proposta Inicial
```java
// AsyncConfig.java - Solu√ß√£o simplista
executor.setCorePoolSize(8);  // Aumentar de 2 ‚Üí 8
executor.setMaxPoolSize(16);  // Aumentar de 4 ‚Üí 16
```

### Cr√≠tica Correta do Usu√°rio
> "eu nao gostei da sua resolucao de problema so aumentando as thread, para mim nao faz sentido pois ainda √© bloqueante"

**Por que a cr√≠tica estava certa**:
- ‚úÖ O problema fundamental (`Thread.sleep()`) continuava
- ‚úÖ Solu√ß√£o n√£o escal√°vel - mais threads = mais mem√≥ria
- ‚úÖ Thread pool maior mascarava mas n√£o resolvia a arquitetura bloqueante
- ‚úÖ Ainda vulnerable a deadlocks sob alta carga

---

## üí° Solu√ß√£o Redis-Based (Segunda Itera√ß√£o)

### Substitui√ß√£o do Thread.sleep() por Redis
```java
// Antes (BLOQUEANTE):
Thread.sleep(retryDelay); 
return retry();

// Depois (N√ÉO-BLOQUEANTE):
reAddToRedisForRetry(campaignContact, retryDelay);
return false; // Thread liberada imediatamente
```

### Implementa√ß√£o do Retry via Redis
```java
private void reAddToRedisForRetry(CampaignContact contact, int retryDelayMs) {
    delaySchedulingService.scheduleTask(contact, retryDelayMs, () -> {
        secureCampaignQueueService.addContactForRetry(
            contact.getCampaign().getId(),
            contact.getId(),
            contact.getCustomer().getCompany().getId().toString()
        );
    });
}
```

**Resultado**: Eliminou o bloqueio, mas ainda n√£o era production-ready.

---

## üöÄ Solu√ß√£o Production-Ready (Itera√ß√£o Final)

### Discuss√£o com IA Externa
Voc√™ pediu uma "descricao desse problema para eu pergutar ao claude web, chatgpt e ao gemini outras solucoes".

**Input da IA Externa**: Solu√ß√£o usando `CompletableFuture`, `Semaphore`, e processamento controlado com backpressure.

### Implementa√ß√£o CompletableFuture + Semaphore

#### 1. Configura√ß√£o de Concorr√™ncia
```java
@Configuration
public class CampaignConfiguration {
    @Bean(name = "campaignConcurrencyLimiter")
    public Semaphore concurrencyLimiter() {
        return new Semaphore(50); // M√°ximo 50 mensagens simult√¢neas
    }
    
    @Bean(name = "queueProcessingLimiter") 
    public Semaphore queueProcessingLimiter() {
        return new Semaphore(10); // M√°ximo 10 processadores de fila
    }
    
    @Bean(name = "scheduledExecutor")
    public ScheduledThreadPoolExecutor scheduledExecutor() {
        ScheduledThreadPoolExecutor executor = new ScheduledThreadPoolExecutor(4);
        executor.setRemoveOnCancelPolicy(true);
        return executor;
    }
}
```

#### 2. CampaignMessagingService com CompletableFuture
```java
@Async("campaignExecutor")
public CompletableFuture<Boolean> sendSingleMessageAsync(CampaignContact contact) {
    if (!validateContact(contact)) {
        return CompletableFuture.completedFuture(false);
    }

    int initialDelay = calculateRandomDelay();
    CompletableFuture<Boolean> future = new CompletableFuture<>();
    
    ScheduledFuture<?> scheduledTask = scheduledExecutor.schedule(() -> {
        sendWithRetry(contact, 1)
            .whenComplete((result, throwable) -> {
                if (throwable != null) {
                    future.completeExceptionally(throwable);
                } else {
                    future.complete(result);
                }
            });
    }, initialDelay, TimeUnit.MILLISECONDS);
    
    return future;
}

private CompletableFuture<Boolean> sendWithRetry(CampaignContact contact, int attempt) {
    return CompletableFuture.supplyAsync(() -> {
        // Envio real da mensagem
        return performActualSend(contact);
    }, scheduledExecutor).thenCompose(result -> {
        if (result || attempt >= properties.getMaxRetries()) {
            return CompletableFuture.completedFuture(result);
        }
        
        // Retry com exponential backoff + jitter
        long retryDelay = calculateRetryDelayWithJitter(attempt);
        CompletableFuture<Boolean> retryFuture = new CompletableFuture<>();
        
        scheduledExecutor.schedule(() -> {
            sendWithRetry(contact, attempt + 1)
                .whenComplete((retryResult, retryThrowable) -> {
                    if (retryThrowable != null) {
                        retryFuture.completeExceptionally(retryThrowable);
                    } else {
                        retryFuture.complete(retryResult);
                    }
                });
        }, retryDelay, TimeUnit.MILLISECONDS);
        
        return retryFuture;
    });
}
```

#### 3. CampaignQueueProcessor com Backpressure
```java
@Component
public class CampaignQueueProcessor {
    private final Semaphore concurrencyLimiter;
    private final AtomicBoolean isProcessing = new AtomicBoolean(false);
    
    @Scheduled(fixedRate = 5000)
    public void processCampaignQueue() {
        if (!isProcessing.compareAndSet(false, true)) {
            return; // J√° processando
        }
        
        try {
            int availablePermits = concurrencyLimiter.availablePermits();
            if (availablePermits == 0) {
                log.warn("Sistema no limite de concorr√™ncia");
                return;
            }
            
            int itemsToProcess = Math.min(BATCH_SIZE, availablePermits);
            List<String> items = popItemsFromQueue(itemsToProcess);
            
            for (String item : items) {
                processItemWithBackpressure(item);
            }
        } finally {
            isProcessing.set(false);
        }
    }
    
    private void processItemWithBackpressure(String itemJson) {
        if (!concurrencyLimiter.tryAcquire()) {
            // Backpressure: devolve √† fila
            redisTemplate.opsForZSet().add(QUEUE_KEY, itemJson, System.currentTimeMillis());
            log.warn("Sistema sobrecarregado, devolvendo item √† fila");
            return;
        }
        
        CompletableFuture<Boolean> future = processQueueItem(itemJson)
            .whenComplete((result, throwable) -> {
                concurrencyLimiter.release(); // Libera permit
                activeTasks.remove(taskId);
            });
            
        activeTasks.put(taskId, future);
    }
}
```

### Funcionalidades Avan√ßadas Implementadas

#### Exponential Backoff com Jitter
```java
private long calculateRetryDelayWithJitter(int attempt) {
    long baseDelay = Math.min(properties.getRetryDelayMs() * (1L << (attempt - 1)), 30000L);
    long jitter = ThreadLocalRandom.current().nextLong(0, baseDelay / 4);
    return baseDelay + jitter;
}
```

#### Recupera√ß√£o Autom√°tica de Mensagens Travadas
```java
@Scheduled(fixedRate = 60000) // A cada minuto
public void recoverStuckMessages() {
    List<Object> processingItems = redisTemplate.opsForList().range(PROCESSING_KEY, 0, -1);
    
    for (Object item : processingItems) {
        if (isStuckWithTimeout(item, currentTime)) {
            removeFromProcessingList(item.toString());
            redisTemplate.opsForZSet().add(QUEUE_KEY, item.toString(), currentTime);
            recoveredCount++;
        }
    }
}
```

#### Graceful Shutdown
```java
@PreDestroy
public void shutdown() {
    isProcessing.set(true); // Para processamento
    queueProcessingLimiter.drainPermits();
    
    if (!activeTasks.isEmpty()) {
        CompletableFuture.allOf(activeTasks.values().toArray(new CompletableFuture[0]))
            .orTimeout(45, TimeUnit.SECONDS)
            .whenComplete((v, t) -> {
                moveProcessingItemsBackToQueue(); // Preserva mensagens
            });
    }
}
```

---

## üìä Resultados Finais

### Testes: 7/7 Sucessos ‚úÖ
```
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0
```

### Performance Melhorada
- **Antes**: 4 contatos = 180s+ (travava ap√≥s 2)
- **Depois**: 4 contatos = 45-135s (processa todos)

### Arquitetura Robusta
- **Zero bloqueio**: CompletableFuture + ScheduledExecutor
- **Controle de concorr√™ncia**: Semaphore com 50 slots
- **Backpressure**: Devolve itens quando sobrecarregado
- **Recupera√ß√£o autom√°tica**: Detecta e reprocessa mensagens travadas
- **Graceful shutdown**: Preserva mensagens em processamento
- **M√©tricas completas**: Monitoring via Micrometer

---

## üéØ Pr√≥ximos Passos (Para Amanh√£)

### Tarefas Pendentes Menores
1. **Limpar logs verbosos**: Remover debug excess do ZApiAdapter
2. **Otimizar ConversationService logs**: Reduzir logging websocket
3. **Monitoring dashboard**: Configurar Grafana/Prometheus (opcional)

### Arquivos Principais Modificados
- `CampaignConfiguration.java` - Configura√ß√£o de concorr√™ncia
- `CampaignQueueProcessor.java` - Processamento com backpressure  
- `CampaignMessagingService.java` - CompletableFuture + retry
- Testes atualizados e passando

### Estado Atual
‚úÖ **Sistema production-ready**  
‚úÖ **Thread Pool Exhaustion resolvido**  
‚úÖ **Arquitetura n√£o-bloqueante implementada**  
‚úÖ **Testes validando funcionalidade**  
‚úÖ **Commit realizado com sucesso**

**Branch**: `RBY-28-disparo-de-mensagem-campanha`  
**√öltimo commit**: `feat: implement production-ready campaign system with advanced concurrency control`